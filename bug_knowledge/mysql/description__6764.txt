{
    "sql": "set sql_mode=''; drop table if exists t; create table `t` ( `a` varchar(100) not null default '', `b` varchar(50) not null default '', `c` varchar(5000) default null, `d` timestamp null default current_timestamp on update current_timestamp, `e` timestamp null default current_timestamp, `f` bigint(25) not null auto_increment, primary key (`f`) ) engine=innodb default charset=latin1; insert into t(a,b,c) values (uuid(),uuid(),uuid()),(uuid(),uuid(),uuid()),(uuid(),uuid(),uuid()),(uuid(),uuid(),uuid()),(uuid(),uuid(),uuid()); insert into t(a,b,c) select concat(rand(),uuid()),concat(rand(),uuid()),concat(rand(),uuid()) from t a,t b,t c,t d,t e,t f,t g,t h,t i,t j; analyze table t; show table status like 't'; select count(*) from t; select data_length+index_length,data_length,index_length from information_schema.tables where table_schema='test' and table_name='t'; update t set c = repeat('a',floor(100*rand())) where b like '0.1%'; update t set c = repeat('b',floor(500*rand())) where b like '0.5%'; delete from t where b like '0.7%'; analyze table t; show table status like 't'; select count(*) from t; select data_length+index_length,data_length,index_length from information_schema.tables where table_schema='test' and table_name='t'; alter table t engine=innodb, algorithm=inplace, lock=none; analyze table t; show table status like 't'; select count(*) from t; select data_length+index_length,data_length,index_length from information_schema.tables where table_schema='test' and table_name='t'; alter table t engine=innodb, algorithm=copy, lock=shared; analyze table t; show table status like 't'; select count(*) from t; select data_length+index_length,data_length,index_length from information_schema.tables where table_schema='test' and table_name='t';",
    "Affected Elements": "alter table, algorithm, analyze table, show table status, information_schema.tables",
    "Root Cause Analysis": "The use of the 'inplace' algorithm during the table rebuild is causing unexpected table size increase due to fragmentation not being handled as effectively as with the 'copy' algorithm."
}