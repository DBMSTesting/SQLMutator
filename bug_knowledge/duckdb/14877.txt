{
    "sql": "COPY (SELECT ALL TRIM(\"COL1\", concat(' ', chr(9), chr(10), chr(13))) AS \"COL1\", IF(TRIM(\"COL2\", concat(' ', chr(9), chr(10), chr(13))) != '', TRIM(\"COL2\", concat(' ', chr(9), chr(10), chr(13))), null) AS \"COL2\" FROM \"DUCKDB_TABLE_NAME\") TO 's3://your-bucket-name/COS_BIG_TABLE.csv' (FORMAT CSV, HEADER false, DELIMITER '|', ESCAPE '^', QUOTE '\"', DATEFORMAT '%Y-%m-%d', TIMESTAMPFORMAT '%Y-%m-%d %H:%M:%S.%f', COMPRESSION 'gzip', NULLSTR 'NULL', USE_TMP_FILE true, FORCE_QUOTE(\"COL1\",\"COL2\"));",
    "Affected Elements": "USE_TMP_FILE, COMPRESSION 'gzip', COPY",
    "Root Cause Analysis": "The underlying issue is likely related to how DuckDB handles temporary files during multipart uploads to S3 when gzip compression is applied, causing uploads to hang and not finalize correctly."
}