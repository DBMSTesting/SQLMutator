ID: 23555
Title: GET_PART replication tasks hang for hours
Description:
ClickHouse 21.4.4

We have now seen this issue twice since upgrading to ClickHouse 21.4.4 about a week ago.  I don't think we saw anything quite like it previously.

On one of our clusters of 10 shards, 4 replicas, within the space of approximately 30 seconds one set GET_PART tasks will execute on multiple tables and multiple shards for relatively small parts.  This group of tasks will simply hang for several hours, until we have to restart the service to clear the replication queues which basically grows out of control (more than 100k entries waiting for the "hung" parts to complete.). 

The hung tasks have only occurred in one of our three datacenters, and since they happen on multiple nodes/shards at approximately the same time it's quite possibly related to a network glitch.

The tasks show as "currently_executing" for three or four hours.  There are no retries, exceptions, or postpone reasons.  Even on restarting the service some of these tasks remain stuck for 20 or 30 minutes, but they do seem to eventually clear and the replication_queue drains.

I've started running the log in debug mode to capture more data assuming it happens again.  There is nothing in the log referencing these stuck parts at the "information" level, our normal mode.

It seems like something happens during the fetch that leaves these tasks orphaned under certain (rare) circumstances, since we do several hundred terabytes of data per day and it's only happened twice.

