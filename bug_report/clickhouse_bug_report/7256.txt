ID: 7256
Title: Data loss on KafkaEngine > MV > replicated table on Too Many Parts error
Description:
**Describe the bug or unexpected behaviour**
We have a two-machine cluster, with replicated tables, one shard. Machines are r5.large. 
We have 23 KafkaEngine tables that consume from those topics from a single 5-node Kafka cluster.
There are materialized views that consume from KafkaEngine tables and put them into ReplicatedReplacingMergeTree tables that are used for a distributed table.

Eventually, consumption from the larger topic of the set got infinitely stuck (several days went by), while the others continued regular consumption. We see in the logs that there were a `Too many parts` error, that keeps appearing, in that topic only, that seems to cause this issue.

So, we have this Too many parts problem, that has been tackled in other CH issues.
However, we were expecting offsets not being committed, but consumption was happening up-to-date with no lag, although data was not being inserted into tables, resulting in data loss. 

**How to reproduce**
* Versions:  19.13.3
* Any large table that would produce `Too many parts` error, following the scenario outlined above.

**Expected behavior**
Offsets should not be advanced (committed) when there is an insertion error such as `Too many parts` error or some other error on the insertion side. 
Also, suggestion for support for configuring the behaviour when this happens (i.e. whether to stop consuming in case of insertion error, or keep consuming).

