ID: 5400
Title: clickhouse-server crashed when insert batch data
Description:
**Describe the bug**
when insert 3 batch data per second to clickhouse,  clickhouse-server crashed with no error log and restart after 28 minutes

**How to reproduce**
 3 batch stream insert per second, one batch data contain 10000 row and per row contains 260 columnsã€‚

**Expected behavior**
clickhouse crashed and clickhouse client  connected failed

**Error message and/or stacktrace**
no errlog

May 24 01:56:11 ip-172-31-45-12 systemd[1]: clickhouse-server.service: Main process exited, code=killed, status=11/SEGV
May 24 01:56:11 ip-172-31-45-12 systemd[1]: clickhouse-server.service: Failed with result 'signal'.


019.05.24 01:32:17.576800 [ 3587 ] {63a776ba-6792-4588-b708-b7fbb088439a} <Debug> MemoryTracker: Peak memory usage (for query): 647.26 MiB.
2019.05.24 01:32:17.576814 [ 3587 ] {63a776ba-6792-4588-b708-b7fbb088439a} <Information> HTTPHandler: Done processing query
2019.05.24 01:56:42.004521 [ 1 ] {} <Information> : Starting ClickHouse 19.5.3.8 with revision 54417
2019.05.24 01:56:42.007178 [ 1 ] {} <Information> Application: starting up
2019.05.24 01:56:42.009131 [ 1 ] {} <Information> StatusFile: Status file /data/status already exists - unclean restart. Contents:
PID: 3188
Started at: 2019-04-29 09:55:01
Revision: 54417

2019.05.24 01:56:42.009200 [ 1 ] {} <Debug> Application: rlimit on number of file descriptors is 500000
2019.05.24 01:56:42.009209 [ 1 ] {} <Debug> Application: Initializing DateLUT.
2019.05.24 01:56:42.009213 [ 1 ] {} <Trace> Application: Initialized DateLUT with time zone `UCT'.
2019.05.24 01:56:42.009754 [ 1 ] {} <Debug> Application: Configuration parameter 'interserver_http_host' doesn't exist or exists and empty. Will use 'ip-172-31-45-12.cn-northwest-1.compute.internal' as replica host.
2019.05.24 01:56:42.013911 [ 1 ] {} <Debug> ConfigReloader: Loading config `/etc/clickhouse-server/users.xml'
2019.05.24 01:56:42.015753 [ 1 ] {} <Information> Application: Loading metadata from /data/
2019.05.24 01:56:42.018907 [ 1 ] {} <Information> DatabaseOrdinary (default): Total 5 tables.
2019.05.24 01:56:42.019933 [ 5 ] {} <Information> BackgroundProcessingPool: Create BackgroundProcessingPool with 16 threads
2019.05.24 01:56:42.021366 [ 5 ] {} <Debug> default.entries_debug2 (Data): Loading data parts
2019.05.24 01:56:42.021565 [ 7 ] {} <Debug> default.entries_debug (Data): Loading data parts
2019.05.24 01:56:42.021660 [ 8 ] {} <Debug> default.entries_partition_test (Data): Loading data parts
2019.05.24 01:56:42.021691 [ 6 ] {} <Debug> default.entries_test (Data): Loading data parts
2019.05.24 01:56:42.021817 [ 4 ] {} <Debug> default.entries (Data): Loading data parts
2019.05.24 01:56:42.023022 [ 5 ] {} <Debug> default.entries_debug2 (Data): Loaded data parts (1 items)
2019.05.24 01:56:42.024843 [ 8 ] {} <Debug> default.entries_partition_test (Data): Loaded data parts (1 items)
2019.05.24 01:56:42.026127 [ 7 ] {} <Debug> default.entries_debug (Data): Loaded data parts (2 items)
2019.05.24 01:56:42.418671 [ 6 ] {} <Debug> default.entries_test (Data): Loaded data parts (175 items)
2019.05.24 01:57:00.950469 [ 4 ] {} <Debug> default.entries (Data): Loaded data parts (11920 items)
2019.05.24 01:57:00.956111 [ 1 ] {} <Information> DatabaseOrdinary (default): Starting up tables.
2019.05.24 01:57:00.965796 [ 5 ] {} <Trace> default.entries (Data): Found 11371 old parts to remove.
**Additional context**

