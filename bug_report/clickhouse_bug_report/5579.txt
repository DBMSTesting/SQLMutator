ID: 5579
Title: High memory usage when joined table has many columns (regression)
Description:
Memory usage of a simple join query seems to increase with the number of columns of the joined table, even if these columns are not in result. The problem can be reproduced in versions 19.3 up to 19.7 (19.1 is fine).

Steps to reproduce:

```
create table A (id String, ts DateTime) ENGINE=MergeTree order by tuple();

insert into A select number,now() from system.numbers limit 600;

create table B (id String, ts DateTime, a0 Nullable(Float64), a1 Nullable(Float64), a2 Nullable(Float64), ... (500 columns) ) ENGINE=MergeTree order by tuple();

insert into B select number,now(),1,1,... (500 values) from system.numbers limit 20000000;

select a.id FROM A a LEFT JOIN B b ON a.id=b.id;

Progress: 1.03 million rows, 4.66 GB (226.75 thousand rows/s., 1.02 GB/s.)  5%Received exception from server (version 19.7.3):
Code: 241. DB::Exception: Received from localhost:9000, 127.0.0.1. DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 131072 bytes), maximum: 9.31 GiB: (while reading column a350)
```

Workaround:
`select a.id FROM A a LEFT JOIN (select id FROM B) b ON a.id=b.id;
`

The problem with the workaround is as the request is generated by a BI (Tableau), I cannot easily modify it.

I've seen this issue https://github.com/yandex/ClickHouse/pull/4757 but the flag multiple_joins_omit_unused_columns doesn't exist in version 19.7??