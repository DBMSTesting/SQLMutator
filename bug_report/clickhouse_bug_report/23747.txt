ID: 23747
Title: Version 21.2.3.15 Received signal Segmentation fault (11)
Description:
**Describe the bug**
ClickHouse crashed when running simple select query (distributed table).

**How to reproduce**
It works fine for several months, before this problem happened. So I'm not sure it can be easily reproduced.
* ClickHouse Version: 21.2.3.15
* Interface: http

* Sample data for all these tables, use [clickhouse-obfuscator]
`
Star Schema Benchmark dataset (about 600 million rows)
`
* Queries to run that lead to unexpected result
`
echo "SELECT LO_ORDERKEY, LO_LINENUMBER, LO_CUSTKEY, LO_PARTKEY from lineorder_flat_distibuted" WHERE S_NATION = 'UNITED STATES' LIMIT 10000 | clickhouse-benchmark
`

**Error message and/or stacktrace**
```
2021.04.28 12:40:21.422964 [ 31710 ] {} <Trace> BaseDaemon: Received signal 11
2021.04.28 12:40:21.423267 [ 31943 ] {} <Fatal> BaseDaemon: ########################################
2021.04.28 12:40:21.423354 [ 31943 ] {} <Fatal> BaseDaemon: (version 21.2.3.15 (official build), build id: 49938CCB63EE2A4E16CF0528307EE15F08469219) (from thread 31727) (no query) Received signal Segmentation fault (11)
2021.04.28 12:40:21.423407 [ 31943 ] {} <Fatal> BaseDaemon: Address: 0x90 Access: read. Address not mapped to object.
2021.04.28 12:40:21.423459 [ 31943 ] {} <Fatal> BaseDaemon: Stack trace: 0xf520ac4 0xf5207e9 0xf52e375 0xf52eab0 0xe6b6207 0xf6434bc 0xf643c89 0xf64355c 0xf643c89 0xf64355c 0xf643c49 0xf647190 0xf64b6c6 0x84ff90f 0x85033a3 0x7f77938b874a 0x7f77935f7f6d
2021.04.28 12:40:21.451042 [ 31943 ] {} <Fatal> BaseDaemon: 2. ext::basic_scope_guard<DB::Connection::receivePacket(std::__1::function<void (Poco::Net::Socket&)>)::$_3>::~basic_scope_guard() @ 0xf520ac4 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.473026 [ 31943 ] {} <Fatal> BaseDaemon: 3. DB::Connection::receivePacket(std::__1::function<void (Poco::Net::Socket&)>) @ 0xf5207e9 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.494101 [ 31943 ] {} <Fatal> BaseDaemon: 4. DB::MultiplexedConnections::receivePacketUnlocked(std::__1::function<void (Poco::Net::Socket&)>) @ 0xf52e375 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.494200 [ 31943 ] {} <Fatal> BaseDaemon: 5. DB::MultiplexedConnections::drain() @ 0xf52eab0 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.494253 [ 31943 ] {} <Fatal> BaseDaemon: 6. DB::RemoteQueryExecutor::finish(std::__1::unique_ptr<DB::RemoteQueryExecutorReadContext, std::__1::default_delete<DB::RemoteQueryExecutorReadContext> >*) @ 0xe6b6207 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.520486 [ 31943 ] {} <Fatal> BaseDaemon: 7. DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::ExecutingGraph::Edge&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, unsigned long) @ 0xf6434bc in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.540833 [ 31943 ] {} <Fatal> BaseDaemon: 8. DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::unique_lock<std::__1::mutex>) @ 0xf643c89 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.540920 [ 31943 ] {} <Fatal> BaseDaemon: 9. DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::ExecutingGraph::Edge&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, unsigned long) @ 0xf64355c in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.540970 [ 31943 ] {} <Fatal> BaseDaemon: 10. DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::unique_lock<std::__1::mutex>) @ 0xf643c89 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541004 [ 31943 ] {} <Fatal> BaseDaemon: 11. DB::PipelineExecutor::tryAddProcessorToStackIfUpdated(DB::ExecutingGraph::Edge&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, unsigned long) @ 0xf64355c in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541044 [ 31943 ] {} <Fatal> BaseDaemon: 12. DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::unique_lock<std::__1::mutex>) @ 0xf643c49 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541072 [ 31943 ] {} <Fatal> BaseDaemon: 13. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0xf647190 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541125 [ 31943 ] {} <Fatal> BaseDaemon: 14. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xf64b6c6 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541159 [ 31943 ] {} <Fatal> BaseDaemon: 15. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x84ff90f in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541190 [ 31943 ] {} <Fatal> BaseDaemon: 16. void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()> >(void*) @ 0x85033a3 in /usr/lib/debug/.build-id/49/938ccb63ee2a4e16cf0528307ee15f08469219.debug
2021.04.28 12:40:21.541226 [ 31943 ] {} <Fatal> BaseDaemon: 17. start_thread @ 0x874a in /lib64/libpthread-2.22.so
2021.04.28 12:40:21.541255 [ 31943 ] {} <Fatal> BaseDaemon: 18. clone @ 0xecf6d in /lib64/libc-2.22.so
2021.04.28 12:40:21.704704 [ 31943 ] {} <Fatal> BaseDaemon: Checksum of the binary: 25543E19223A073C0743A2BE2F4FF732, integrity check passed.
```
**Additional context**
10 nodes for clickhouse (5 shards 2 replicas) ; 3 nodes for zookeeper


