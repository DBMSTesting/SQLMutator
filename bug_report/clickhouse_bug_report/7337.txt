ID: 7337
Title: Clickhouse MV with Array Join from Kafka Engine Table
Description:
Hi. 
On the last Clickhouse server version 19.15.3 we observe the next bug.
We have such schema:
Kafka Engine Table -> MV To Table (with Array Join) -> Destination Merge Tree Table. 
And on the MV layer we get such error:
```
 <Error> void DB::StorageKafka::threadFunc(): Code: 9, e.displayText() = DB::Exception: Size of offsets doesn't match size of column.: while pushing to view test.TestTableView, Stack trace:

0. 0x5601f2a75640 StackTrace::StackTrace() /usr/bin/clickhouse
1. 0x5601f2a75415 DB::Exception::Exception(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) /usr/bin/clickhouse
2. 0x5601f2834009 ? /usr/bin/clickhouse
3. 0x5601f64f5401 DB::ExpressionAction::execute(DB::Block&, bool) const /usr/bin/clickhouse
4. 0x5601f64f6335 DB::ExpressionActions::execute(DB::Block&, bool) const /usr/bin/clickhouse
5. 0x5601f638f4db DB::ExpressionBlockInputStream::readImpl() /usr/bin/clickhouse
6. 0x5601f5c82d67 DB::IBlockInputStream::read() /usr/bin/clickhouse
7. 0x5601f638f4bf DB::ExpressionBlockInputStream::readImpl() /usr/bin/clickhouse
8. 0x5601f5c82d67 DB::IBlockInputStream::read() /usr/bin/clickhouse
9. 0x5601f63a4eea DB::MaterializingBlockInputStream::readImpl() /usr/bin/clickhouse
10. 0x5601f5c82d67 DB::IBlockInputStream::read() /usr/bin/clickhouse
11. 0x5601f5c9e616 DB::SquashingBlockInputStream::readImpl() /usr/bin/clickhouse
12. 0x5601f5c82d67 DB::IBlockInputStream::read() /usr/bin/clickhouse
13. 0x5601f6371748 DB::ConvertingBlockInputStream::readImpl() /usr/bin/clickhouse
14. 0x5601f5c82d67 DB::IBlockInputStream::read() /usr/bin/clickhouse
15. 0x5601f63cdfaf DB::PushingToViewsBlockOutputStream::process(DB::Block const&, unsigned long) /usr/bin/clickhouse
16. 0x5601f63ce9c2 DB::PushingToViewsBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse
17. 0x5601f63556bf DB::AddingDefaultBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse
18. 0x5601f6373eac DB::CountingBlockOutputStream::write(DB::Block const&) /usr/bin/clickhouse
19. 0x5601f5c9fec5 DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::atomic<bool>*) /usr/bin/clickhouse
20. 0x5601f631c42e DB::StorageKafka::streamToViews() /usr/bin/clickhouse
21. 0x5601f631cb91 DB::StorageKafka::threadFunc() /usr/bin/clickhouse
22. 0x5601f6322869 DB::BackgroundSchedulePoolTaskInfo::execute() /usr/bin/clickhouse
23. 0x5601f63231aa DB::BackgroundSchedulePool::threadFunction() /usr/bin/clickhouse
24. 0x5601f632322a ? /usr/bin/clickhouse
25. 0x5601f2abe61c ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>) /usr/bin/clickhouse
26. 0x5601f8785eb0 ? /usr/bin/clickhouse
27. 0x7f8cdef58494 start_thread /lib/x86_64-linux-gnu/libpthread-2.24.so
28. 0x7f8cde88eacf clone /lib/x86_64-linux-gnu/libc-2.24.so
```

Experimental way shows that the reason of such error are Array Joins in MV. For example if we use instead of Kafka Engine Table simple Null table - MV with array join works well. Plus, such a schema with Kafka Engine Source also works well on older Clickhouse server versions, for example 19.9.2. 
Need to say, that we insert data in Native format.
