ID: 18844
Title: CRITICAL: DATA CORRUPTION on merges using linux AIO 
Description:
**Describe the bug**
After upgrading to clickhouse 20.12.4.5 we started seeing some merge errors, that lead to data loss.
The main error message is :

``` 
2021.01.04 20:05:15.716664 [ 149272 ] {} <Error> virtual DB::WriteBufferAIO::~WriteBufferAIO(): Code: 49, e.displayText() = DB::Exception: An overflow occurred during file operation, Stack trace (when copying this message, always include the lines below):

0. DB::WriteBufferAIO::finalize() @ 0xd836f34 in /usr/bin/clickhouse
1. DB::WriteBufferAIO::~WriteBufferAIO() @ 0xd835f2a in /usr/bin/clickhouse
2. DB::WriteBufferAIO::~WriteBufferAIO() @ 0xd836639 in /usr/bin/clickhouse
3. DB::MergeTreeDataPartWriterOnDisk::Stream::~Stream() @ 0xe3e0a22 in /usr/bin/clickhouse
4. std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > > > >::destroy(std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, void*>*) @ 0xe3ea38c in /usr/bin/clickhouse
5. std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > > > >::destroy(std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<DB::MergeTreeDataPartWriterOnDisk::Stream, std::__1::default_delete<DB::MergeTreeDataPartWriterOnDisk::Stream> > >, void*>*) @ 0xe3ea373 in /usr/bin/clickhouse
6. DB::MergeTreeDataPartWriterWide::finishDataSerialization(DB::MergeTreeDataPartChecksums&, bool) @ 0xe3e9e3f in /usr/bin/clickhouse
7. DB::MergedBlockOutputStream::writeSuffixAndFinalizePart(std::__1::shared_ptr<DB::IMergeTreeDataPart>&, bool, DB::NamesAndTypesList const*, DB::MergeTreeDataPartChecksums*) @ 0xe4a439c in /usr/bin/clickhouse
8. DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart(DB::FutureMergedMutatedPart const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::BackgroundProcessListEntry<DB::MergeListElement, DB::MergeInfo>&, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, long, DB::Context const&, std::__1::unique_ptr<DB::IReservation, std::__1::default_delete<DB::IReservation> > const&, bool) @ 0xe3a6234 in /usr/bin/clickhouse
9. DB::StorageReplicatedMergeTree::tryExecuteMerge(DB::ReplicatedMergeTreeLogEntry const&) @ 0xe18f0bd in /usr/bin/clickhouse
10. DB::StorageReplicatedMergeTree::executeLogEntry(DB::ReplicatedMergeTreeLogEntry&) @ 0xe1842dc in /usr/bin/clickhouse
11. ? @ 0xe1f1aac in /usr/bin/clickhouse
12. DB::ReplicatedMergeTreeQueue::processEntry(std::__1::function<std::__1::shared_ptr<zkutil::ZooKeeper> ()>, std::__1::shared_ptr<DB::ReplicatedMergeTreeLogEntry>&, std::__1::function<bool (std::__1::shared_ptr<DB::ReplicatedMergeTreeLogEntry>&)>) @ 0xe4f24e5 in /usr/bin/clickhouse
13. DB::StorageReplicatedMergeTree::processQueueEntry(std::__1::shared_ptr<DB::ReplicatedMergeTreeQueue::SelectedEntry>) @ 0xe1ad34a in /usr/bin/clickhouse
14. ? @ 0xe1f2625 in /usr/bin/clickhouse
15. ? @ 0xe301dfd in /usr/bin/clickhouse
16. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x7d285ed in /usr/bin/clickhouse
17. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x7d2ab4f in /usr/bin/clickhouse
18. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x7d25aad in /usr/bin/clickhouse
19. ? @ 0x7d295d3 in /usr/bin/clickhouse
20. start_thread @ 0x7fa3 in /usr/lib/x86_64-linux-gnu/libpthread-2.28.so
21. __clone @ 0xf94cf in /usr/lib/x86_64-linux-gnu/libc-2.28.so
 (version 20.12.4.5 (official build))
```

Some fact about the errors : 
- it seems deterministic. When a merge fails on master, a later merge fails on replica.
- it  happens at the end of merge data stream.
- so far, i have only detected the issue on the data files, not mark or indice files. All of them are wide format, but i guess it means nothing as our merges are too big to be compact anyway. 
- Despite the error message about file offset overflow, the part files are relatively small (between 200MB and 5G). So i can only assume it is actually an inconsistent update of the file offset that leads to underflow in the comparaison ?
- all cases i was able to investigate (a small percentage actually) seems to happen on the same column of type `String CODEC(ZSTD(1)),` this column is quite big.
- idk if related, but the column that causes issue has a data skipping index : ` TYPE ngrambf_v1(4, 256, 3, 15605745448044353074) GRANULARITY 3` 
- in broken_, the file is indeed corrupted at the end, with a lot of 0fill, a few kb to 256kb of zeros. 
- max_compressed_block_size is default value (1M), and strace confirms io_submit of roughly ~1 040 000
- it might be related to the change to max_compressed_block_size (so that it is now taken into account), because we ran a patched version internally with this change while testing https://github.com/ClickHouse/ClickHouse/pull/17184 and i can see the same error happening while digging some logs (unfortunately we didn't detect it back then :( ) , while when we reverted to stable clickhouse meanwhile the error did not occur until we upgraded to this version
- for the record, we run on 5.8, debian buster, but there is no evidence of aio misbehaving by himself, the issue seems to come from a code issue/race on part finalization of the. 
- there is no sign of hardware issue, no mce no ECC error, disk are reported healthy, and this happens cluster wide accross multiple servers. 

Additionally, this is bad because replication does NOT protect from this issue, though it might mandate an over issue. We see merge failing on one replica, but for some reason, while part is moved to detached/broken_, the source part are deleted, but the deletion is not synced to replica (since the merged part cannot be fetched, i guess). Unfortunately, the merge is tried again later on the replica, and this time, there is no over replica, so when the source part are removed,the data is fully corrupted/loss.

I'll try to post more details, but i wanted to PSA about this issue. 
