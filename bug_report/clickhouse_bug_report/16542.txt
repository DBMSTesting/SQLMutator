ID: 16542
Title: distributed ddl failed after upgrade
Description:
I have a cluster with 6 node, I upgrade to node from 20.3.5.21 to 20.6.8.5

After the upgrade, I found that distributed DDL cannot be executed
```
bj2-all-clickhouse-test-01 :) alter table  bp_forkgio.action_fork_local on cluster ck_cluster delete where D_SEND_TIME>='2020-10-29 00:00:00' and D_SEND_TIME<'2020-10-29 23:59:59';

ALTER TABLE bp_forkgio.action_fork_local ON CLUSTER ck_cluster
    DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59')


┌─host───────────────────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐
│ bj2-all-clickhouse-test-02 │ 9000 │      0 │       │                   5 │                3 │
│ bj2-all-clickhouse-test-01 │ 9000 │      0 │       │                   4 │                3 │
│ bj2-all-clickhouse-test-02 │ 9002 │      0 │       │                   3 │                3 │
└────────────────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘
┌─host───────────────────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐
│ bj2-all-clickhouse-test-01 │ 9002 │      0 │       │                   2 │                2 │
└────────────────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘
↘ Progress: 4.00 rows, 280.00 B (7.71 rows/s., 539.56 B/s.)  66%Received exception from server (version 20.3.4):
Code: 159. DB::Exception: Received from localhost:9000. DB::Exception: Watching task /clickhouse/task_queue/ddl/query-0000021853 is executing longer than distributed_ddl_task_timeout (=180) seconds. There are 2 unfinished hosts (2 of them are currently active), they are going to execute the query in background. 

4 rows in set. Elapsed: 180.070 sec. 
```
log
```
2020.10.30 16:30:24.242754 [ 22956 ] {9717bc2f-73e2-4157-b966-93e31059bed3} <Debug> executeQuery: (from 127.0.0.1:42620) ALTER TABLE bp_forkgio.action_fork_local ON CLUSTER ck_cluster DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59') 
2020.10.30 16:30:24.254011 [ 27027 ] {edc23bc0-c9f1-4e6f-bd96-4f3ce6995425} <Debug> DDLWorker: Processing tasks
2020.10.30 16:30:24.255286 [ 22956 ] {9717bc2f-73e2-4157-b966-93e31059bed3} <Debug> executeQuery: Query pipeline:
DDLQueryStatusInputStream

2020.10.30 16:30:24.257931 [ 27027 ] {edc23bc0-c9f1-4e6f-bd96-4f3ce6995425} <Debug> DDLWorker: Processing task query-0000021853 (ALTER TABLE bp_forkgio.action_fork_local ON CLUSTER ck_cluster DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:
59:59') )
2020.10.30 16:30:24.259225 [ 27027 ] {edc23bc0-c9f1-4e6f-bd96-4f3ce6995425} <Debug> DDLWorker: Executing query: ALTER TABLE bp_forkgio.action_fork_local DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59') 
2020.10.30 16:30:24.271734 [ 27027 ] {9c33f97a-f278-4b3a-8929-176a9f94e43b} <Debug> executeQuery: (from 0.0.0.0:0, user: ) /* ddl_entry=query-0000021853 */ ALTER TABLE bp_forkgio.action_fork_local DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-2
9 23:59:59') 
2020.10.30 16:30:24.272113 [ 27027 ] {9c33f97a-f278-4b3a-8929-176a9f94e43b} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition "NOT ((D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59'))" moved to PREWHERE
2020.10.30 16:30:24.288560 [ 26951 ] {} <Information> bp_forkgio.action_fork_local (ReplicatedMergeTreeQueue): Loading 1 mutation entries: 0000000212 - 0000000212
2020.10.30 16:30:24.289233 [ 27027 ] {9c33f97a-f278-4b3a-8929-176a9f94e43b} <Debug> DDLWorker: Executed query: ALTER TABLE bp_forkgio.action_fork_local DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59') 
2020.10.30 16:30:24.293960 [ 27027 ] {9c33f97a-f278-4b3a-8929-176a9f94e43b} <Debug> DDLWorker: Waiting a watch
2020.10.30 16:30:24.295576 [ 26952 ] {} <Debug> bp_forkgio.action_fork_local (ReplicatedMergeTreeQueue): Pulling 1 entries to queue: log-0000007142 - log-0000007142
2020.10.30 16:30:24.298227 [ 26952 ] {} <Debug> bp_forkgio.action_fork_local (ReplicatedMergeTreeQueue): Pulled 1 entries to queue.
2020.10.30 16:30:24.298546 [ 26944 ] {} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 176.15 GiB.
2020.10.30 16:30:24.299008 [ 26944 ] {} <Debug> bp_forkgio.action_fork_local (SelectExecutor): Key condition: unknown, unknown, and
2020.10.30 16:30:24.299021 [ 26944 ] {} <Debug> bp_forkgio.action_fork_local (SelectExecutor): MinMax index condition: unknown, unknown, and
2020.10.30 16:30:24.299034 [ 26944 ] {} <Debug> bp_forkgio.action_fork_local (SelectExecutor): Selected 1 parts by date, 1 parts by key, 1 marks to read from 1 ranges
2020.10.30 16:30:24.300737 [ 26944 ] {} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 176.15 GiB.
2020.10.30 16:30:24.300769 [ 26944 ] {} <Debug> bp_forkgio.action_fork_local: Cloning part /data/clickhouse/node1/data/bp_forkgio/action_fork_local/202010_0_5999_1123_6003/ to /data/clickhouse/node1/data/bp_forkgio/action_fork_local/tmp_clone_202010_0_5999_1123_6004
2020.10.30 16:30:24.307087 [ 26956 ] {} <Debug> bp_forkgio.action_fork_local: Trying to finalize mutations
2020.10.30 16:30:25.309345 [ 26929 ] {} <Debug> bp_forkgio.action_fork_local: Trying to finalize mutations





2020.10.30 16:33:24.312251 [ 22956 ] {9717bc2f-73e2-4157-b966-93e31059bed3} <Error> executeQuery: Code: 159, e.displayText() = DB::Exception: Watching task /clickhouse/task_queue/ddl/query-0000021853 is executing longer than distributed_ddl_task_timeout (=180) seconds. There are 2 unfinished hosts (2 of them are currently active), they are going to execute the query in background (version 20.3.4.10 (official build)) (from 127.0.0.1:42620) (in query: ALTER TABLE bp_forkgio.action_fork_local ON CLUSTER ck_cluster DELETE WHERE (D_SEND_TIME >= '2020-10-29 00:00:00') AND (D_SEND_TIME < '2020-10-29 23:59:59') ), Stack trace (when copying this message, always include the lines below):

0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x102e0d8c in /usr/bin/clickhouse
1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8f2d989 in /usr/bin/clickhouse
2. DB::DDLQueryStatusInputStream::readImpl() @ 0xce9b253 in /usr/bin/clickhouse
3. DB::IBlockInputStream::read() @ 0xccd503f in /usr/bin/clickhouse
4. DB::AsynchronousBlockInputStream::calculate() @ 0xcccc124 in /usr/bin/clickhouse
5. ? @ 0xcccd8e4 in /usr/bin/clickhouse
6. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8f51c4b in /usr/bin/clickhouse
7. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() const @ 0x8f528c4 in /usr/bin/clickhouse
8. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8f50b4b in /usr/bin/clickhouse
9. ? @ 0x8f4f00f in /usr/bin/clickhouse
10. start_thread @ 0x7dd5 in /usr/lib64/libpthread-2.17.so
11. clone @ 0xfdead in /usr/lib64/libc-2.17.so
```

~~I restarted the two upgraded nodes. Distributed DDL can be executed within a short time after restarting, but it will not work after a while~~


I did some more tests. It is okay to execute statements such as create/drop xx on cluster, but only if I execute this alter table delete, I will encounter the above error, and all subsequent create/drop xx on clusters are also Will encounter the same problem, until I restart the node to recover

I think maybe the problem is that i use clickhouse-client 20.3.5.21?

