ID: 70212
Title: LIMIT clause slows down select queries in tables with light-weight deletes
Description:
Let's create two files:

```
import pandas as pd
import numpy as np
df = pd.DataFrame(np.ones(10000000, dtype=int), columns=['example_column'])
df.to_csv(f"{user_files}/ones.csv", index = False)
df = pd.DataFrame(2 * np.ones(3, dtype=int), columns=['example_column'])
df.to_csv(f"{user_files}/twos.csv", index = False)
```

```
CREATE TABLE example
(
    `example_column` UInt32
) ENGINE MergeTree()
PRIMARY KEY (example_column)
ORDER BY (example_column)
SETTINGS index_granularity = 8192
INSERT INTO example(example_column) SELECT example_column  FROM file(f"{user_files}/ones.csv');
INSERT INTO example(example_column) SELECT example_column  FROM file(f"{user_files}/twos.csv');
DELETE FROM example WHERE example_column = 1;
```

```
 SELECT example_column from example; - WORKS fast
 SELECT example_column from example LIMIT 1; - WORKS very slow
```

The bug is present in queries with both new and old analyzer
