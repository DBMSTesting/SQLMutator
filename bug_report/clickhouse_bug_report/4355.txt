ID: 4355
Title: Number of file descriptor overflow with StorageKafka 
Description:
A large number of file descriptors created and ending up crashing the clickhouse server
Error logs files contains
`2019.02.11 15:59:13.927576 [ 502528 ] {} <Error> ServerErrorHandler: Poco::Exception. Code: 1000, e.code() = 24, e.displayText() = I/O error: Too many open files, e.what() = I/O error
2019.02.11 15:59:13.930292 [ 503437 ] {} <Error> ServerErrorHandler: Poco::Exception. Code: 1000, e.code() = 24, e.displayText() = I/O error: Too many open files, e.what() = I/O error
` 
How to reproduce:
ClickHouse server version: 19.1.6 with command line Client
Setup kafka table as in this documentation:
https://clickhouse.yandex/docs/en/operations/table_engines/kafka/

1. Create a table with kafka engine with consumer > 1
2. Create a regular table to store the message from this consumer table
3. create a materialized view 

To check if the number of fd is increasing:
Get the pid:
`ps aux | grep clickhouse`

`lsof <pid>`
you can see a lot of messages like
clickhous 12924 root  898u  netlink                          0t0 21106707 GENERIC
clickhous 12924 root  899u  netlink                          0t0 21092604 GENERIC
clickhous 12924 root  900u  netlink                          0t0 21100661 GENERIC
clickhous 12924 root  901u  netlink                          0t0 21093565 GENERIC
clickhous 12924 root  902u  netlink                          0t0 21081672 GENERIC

The rate of increase of file descriptor is total number of consumers  x materialized view referesh per second. it's just a matter of time it would reach the limit and it could take a few days for low number of consumers.

Related issue is #3198 and #4017 
We also get to a debugging step that `TaskStatsInfoGetter::~TaskStatsInfoGetter()` did not get called with gdb.
