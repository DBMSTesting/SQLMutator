ID: 23508
Title: Can't attach table with Int64 partitioning key in ClickHouse v21.3
Description:
We're trying to upgrade ClickHouse server from v20.11.7.16 to v21.3.6.55-lts (VERSION_GITHASH 11776e90d9a085ee94bde649c3e9d28105b483c0)

We have following table:

```
CREATE TABLE db.table
(
    `id` Int64,
    `field2` String,
    `field3` IPv4,
    `field4` Nullable(String),
    `field5` Nullable(String),
    `field6` Nullable(String),
    `field7` Nullable(String),
    `field8` Nullable(String),
    `field9` Int8 DEFAULT CAST(0, 'Int8'),
    `field10` Nullable(DateTime),
    `field11` Nullable(DateTime)
)
ENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/{shard}/db/table', '{replica}')
PARTITION BY id % 100
ORDER BY (id, field2, field3)
SAMPLE BY id
SETTINGS index_granularity = 8192
```

On ClickHouse v20.11.7.16 `check table` command is successfull (result = 1), after upgrading ClickHouse server to v21.3.6.55-lts, described table can't be attached with a following error:
```
Code: 33. DB::Exception: Received from localhost:9000. DB::Exception: Cannot read all data. Bytes read: 1. Bytes expected: 2..  
```
<details>
  <summary>Stacktrace</summary>

```

2021.04.23 11:36:06.607482 [ 4851 ] {229c7152-a8fc-42bc-a09c-d3de7d7ba776} <Error> executeQuery: Code: 33, e.displayText() = DB::Exception: Cannot read all data. Bytes read: 1. Bytes expected: 2. (version 21.3.6.55) (from 127.0.0.1:53640) (in query: alter t
able db.table attach part '0_0_97_4';), Stack trace (when copying this message, always include the lines below):

0. DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x868b8bb in /usr/bin/clickhouse
1. DB::DataTypeNumberBase<short>::deserializeBinary(DB::Field&, DB::ReadBuffer&) const @ 0xea35a3a in /usr/bin/clickhouse
2. DB::MergeTreePartition::load(DB::MergeTreeData const&, std::__1::shared_ptr<DB::IDisk> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0xf7a7614 in /usr/bin/clickhouse                              
3. DB::IMergeTreeDataPart::loadPartitionAndMinMaxIndex() @ 0xf668035 in /usr/bin/clickhouse
4. DB::IMergeTreeDataPart::loadColumnsChecksumsIndexes(bool, bool) @ 0xf66409c in /usr/bin/clickhouse
5. DB::MergeTreeData::tryLoadPartsToAttach(std::__1::shared_ptr<DB::IAST> const&, bool, DB::Context const&, DB::MergeTreeData::PartsTemporaryRename&) @ 0xf6c60f8 in /usr/bin/clickhouse
6. DB::StorageMergeTree::attachPartition(std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, bool, DB::Context const&) @ 0xf472e0a in /usr/bin/clickhouse                                                    
7. DB::MergeTreeData::alterPartition(std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::vector<DB::PartitionCommand, std::__1::allocator<DB::PartitionCommand> > const&, DB::Context const&) @ 0xf6bf4a3 in /usr/bin/clickhouse          
8. DB::InterpreterAlterQuery::execute() @ 0xecf308e in /usr/bin/clickhouse
9. ? @ 0xf1f7162 in /usr/bin/clickhouse
10. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xf1f5aa3 in /usr/bin/clickhouse                                                 
11. DB::TCPHandler::runImpl() @ 0xf98402d in /usr/bin/clickhouse
12. DB::TCPHandler::run() @ 0xf996599 in /usr/bin/clickhouse
13. Poco::Net::TCPServerConnection::start() @ 0x1205a0ef in /usr/bin/clickhouse
14. Poco::Net::TCPServerDispatcher::run() @ 0x1205bb01 in /usr/bin/clickhouse
15. Poco::PooledThread::run() @ 0x12192cf9 in /usr/bin/clickhouse
16. Poco::ThreadImpl::runnableEntry(void*) @ 0x1218eb5a in /usr/bin/clickhouse
17. start_thread @ 0x7494 in /lib/x86_64-linux-gnu/libpthread-2.24.so
18. clone @ 0xe8aff in /lib/x86_64-linux-gnu/libc-2.24.so

2021.04.23 11:36:06.608307 [ 4851 ] {229c7152-a8fc-42bc-a09c-d3de7d7ba776} <Error> TCPHandler: Code: 33, e.displayText() = DB::Exception: Cannot read all data. Bytes read: 1. Bytes expected: 2., Stack trace:

0. DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x868b8bb in /usr/bin/clickhouse
1. DB::DataTypeNumberBase<short>::deserializeBinary(DB::Field&, DB::ReadBuffer&) const @ 0xea35a3a in /usr/bin/clickhouse
2. DB::MergeTreePartition::load(DB::MergeTreeData const&, std::__1::shared_ptr<DB::IDisk> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0xf7a7614 in /usr/bin/clickhouse                              
3. DB::IMergeTreeDataPart::loadPartitionAndMinMaxIndex() @ 0xf668035 in /usr/bin/clickhouse
4. DB::IMergeTreeDataPart::loadColumnsChecksumsIndexes(bool, bool) @ 0xf66409c in /usr/bin/clickhouse
5. DB::MergeTreeData::tryLoadPartsToAttach(std::__1::shared_ptr<DB::IAST> const&, bool, DB::Context const&, DB::MergeTreeData::PartsTemporaryRename&) @ 0xf6c60f8 in /usr/bin/clickhouse                                                                        
6. DB::StorageMergeTree::attachPartition(std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, bool, DB::Context const&) @ 0xf472e0a in /usr/bin/clickhouse                                                    
7. DB::MergeTreeData::alterPartition(std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::vector<DB::PartitionCommand, std::__1::allocator<DB::PartitionCommand> > const&, DB::Context const&) @ 0xf6bf4a3 in /usr/bin/clickhouse          
8. DB::InterpreterAlterQuery::execute() @ 0xecf308e in /usr/bin/clickhouse
9. ? @ 0xf1f7162 in /usr/bin/clickhouse
10. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xf1f5aa3 in /usr/bin/clickhouse                                                 
11. DB::TCPHandler::runImpl() @ 0xf98402d in /usr/bin/clickhouse
12. DB::TCPHandler::run() @ 0xf996599 in /usr/bin/clickhouse
13. Poco::Net::TCPServerConnection::start() @ 0x1205a0ef in /usr/bin/clickhouse
14. Poco::Net::TCPServerDispatcher::run() @ 0x1205bb01 in /usr/bin/clickhouse
15. Poco::PooledThread::run() @ 0x12192cf9 in /usr/bin/clickhouse
16. Poco::ThreadImpl::runnableEntry(void*) @ 0x1218eb5a in /usr/bin/clickhouse
17. start_thread @ 0x7494 in /lib/x86_64-linux-gnu/libpthread-2.24.so
18. clone @ 0xe8aff in /lib/x86_64-linux-gnu/libc-2.24.so


```

</details>

All table's parts considered as broken, server can't start automatically
```
2021.04.22 17:38:43.892315 [ 8296 ] {} <Error> Application: Caught exception while loading metadata: Code: 231, e.displayText() = DB::Exception: Suspiciously many (50) broken parts to remove.: Cannot attach table `db`.`table` from metadata file /var/lib/clickhouse/metadata/db/table.sql from query ATTACH TABLE...
```
After touching `force_restore_data` flag server can be started, but data can't be fetched from the replica with an error, shown above.

Tried:
a) Bring knowingly healthy part (passing `check table` command) from another cluster running v20.11.7.16 and attach it - same error.
b) Disable WAL as recommended in https://github.com/ClickHouse/ClickHouse/issues/17762#issuecomment-738106154 - same error


> Bytes read: 1. Bytes expected: 2

From the error message i supposed that 2nd expected byte is a sign, so ClickHouse may be working fine with `UInt*` types.

I tried following:
a) Create table in v20.11.7.16 and v21.3.6.55-lts with `UInt64` type for partitioning key column:
```
CREATE TABLE test.table
(
    `id` UInt64,
    `field2` String,
    `field3` IPv4,
    `field4` Nullable(String),
    `field5` Nullable(String),
    `field6` Nullable(String),
    `field7` Nullable(String),
    `field8` Nullable(String),
    `field9` Int8 DEFAULT CAST(0, 'Int8'),
    `field10` Nullable(DateTime),
    `field11` Nullable(DateTime)
)
ENGINE = ReplacingMergeTree()
PARTITION BY id % 100
ORDER BY (id, field2, field3)
SAMPLE BY id
SETTINGS index_granularity = 8192
```
b) On server with v20.11.7.16: copy data from original table to the new table `test.table` with `INSERT ... SELECT`. Make `OPTIMIZE ... FINAL` for the new table.
c) Copy one part of data from v20.11.7.16 to v21.3.6.55-lt and attach it to the new table.

And it works. Seems like v21 doesn't handle `Int*` types correctly for a custom partitioning key, but there are no limitations described in the doc: https://clickhouse.tech/docs/en/single/#custom-partitioning-key

