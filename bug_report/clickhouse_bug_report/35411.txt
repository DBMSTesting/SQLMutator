ID: 35411
Title: Virtual columns missing in s3 table function
Description:
With clickhouse/clickhouse-server:22.3.2.2 I can no longer access `_file` and `_path` virtual columns on s3() table function like I could with clickhouse/clickhouse-server:22.2.2.1. 

> A clear and concise description of what works not as it is supposed to.

This worked on previous release

```sql
SELECT _path FROM s3('https://host.domain.com/bucket/path/file.parquet') LIMIT 1;
-- Returns --
bucket/path/file.parquet
```

But instead with 22.3 I get

```sql
SELECT _path FROM s3('https://host.domain.com/bucket/path/file.parquet') LIMIT 1;
-- Returns --
Received exception from server (version 22.3.2):
Code: 8. DB::Exception: Received from localhost:9000. DB::Exception: Column '_path' is not presented in input data.: While executing ParquetBlockInputFormat: While executing S3. (THERE_IS_NO_COLUMN)
```

I also have the same behavior on `_file` virtual column. DESCRIBE and retireving data works as I would expect otherwise.

**How to reproduce**

* Which ClickHouse server version to use
    * 22.3.2.2 (`clickhouse/clickhouse-server:22.3.2.2` docker image) 
* Which interface to use, if matters
    * ` docker exec -it <clickhouse-container> clickhouse-client`
* Non-default settings, if any
    * Only added authentication to s3 endpoints
* `CREATE TABLE` statements for all tables involved
    * No tables created
* Sample data for all these tables, use [clickhouse-obfuscator](https://github.com/ClickHouse/ClickHouse/blob/master/programs/obfuscator/Obfuscator.cpp#L42-L80) if necessary
     * No cannot provide s3 link
* Queries to run that lead to unexpected result
    * `SELECT _path FROM s3('https://host.domain.com/bucket/path/file.parquet') LIMIT 1;`

**Expected behavior**

> A clear and concise description of what you expected to happen.

The same behavior as ClickHouse 22.2 that I get the path of the file that the row originates from with `_path` virtual column and the file name with `_file`.

**Error message and/or stacktrace**

```
2022.03.18 15:06:09.951316 [ 45 ] {e874adec-e4ec-4d97-95aa-cc63273472fa} <Error> TCPHandler: Code: 8. DB::Exception: Column '_path' is not presented in input data.: While executing ParquetBlockInputFormat: While executing S3. (THERE_IS_NO_COLUMN), Stack trace (when copying this message, always include the lines below):

0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa4dde1a in /usr/bin/clickhouse
1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&>(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0xa54a504 in /usr/bin/clickhouse
2. DB::ArrowColumnToCHColumn::getMissingColumns(arrow::Schema const&) const @ 0x154d358f in /usr/bin/clickhouse
3. DB::ParquetBlockInputFormat::prepareReader() @ 0x1558744e in /usr/bin/clickhouse
4. DB::ParquetBlockInputFormat::generate() @ 0x15586c72 in /usr/bin/clickhouse
5. DB::ISource::tryGenerate() @ 0x1548cdf5 in /usr/bin/clickhouse
6. DB::ISource::work() @ 0x1548c9ba in /usr/bin/clickhouse
7. DB::ExecutionThreadContext::executeTask() @ 0x154ad143 in /usr/bin/clickhouse
8. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x154a0b9e in /usr/bin/clickhouse
9. DB::PipelineExecutor::executeStep(std::__1::atomic<bool>*) @ 0x154a03c0 in /usr/bin/clickhouse
10. DB::PullingPipelineExecutor::pull(DB::Chunk&) @ 0x154b1c6e in /usr/bin/clickhouse
11. DB::StorageS3Source::generate() @ 0x14c8774c in /usr/bin/clickhouse
12. DB::ISource::tryGenerate() @ 0x1548cdf5 in /usr/bin/clickhouse
13. DB::ISource::work() @ 0x1548c9ba in /usr/bin/clickhouse
14. DB::SourceWithProgress::work() @ 0x156e4282 in /usr/bin/clickhouse
15. DB::ExecutionThreadContext::executeTask() @ 0x154ad143 in /usr/bin/clickhouse
16. DB::PipelineExecutor::executeStepImpl(unsigned long, std::__1::atomic<bool>*) @ 0x154a0b9e in /usr/bin/clickhouse
17. ? @ 0x154a2504 in /usr/bin/clickhouse
18. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa584c97 in /usr/bin/clickhouse
19. ? @ 0xa58881d in /usr/bin/clickhouse
20. ? @ 0x7f4462478609 in ?
21. __clone @ 0x7f446239d163 in ?
```

**Additional context**

> Add any other context about the problem here.

I did not test this with Amazon S3 in this case but instead with a local deployment of Minio running docker image `minio/minio:RELEASE.2020-02-07T04-56-50Z`. This is an old version but it worked fine with the old ClickHouse release. I will try with a real Amazon S3 endpoint as soon as I am able to.
