ID: 52049
Title: disk_snapshot_backup: init pod may get stuck due to concurrency call to `Send`
Description:
## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
Run a disk snapshot backup in a cluster that huge enough.
(Or just injecting some failpoints that make sometimes renewing the lease and sending wait apply happens concurrently.

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
It should success to prepare -- nothing wrong happens. 

### 3. What did you see instead (Required)
We were stuck at sending wait apply. When applying for quotas.
![CleanShot 2024-03-25 at 11 13 01@2x](https://github.com/pingcap/tidb/assets/36239017/60f47606-3c99-42cc-b206-841d2bbf20ef)

### 4. What is your TiDB version? (Required)
v6.5.x
But this may still happen in master.

### NOTE
We call `Send` concurrently over a stream. Which isn't safe according to the document of `ClientStream`:
```go
// It is safe to have a goroutine calling SendMsg and another goroutine
// calling RecvMsg on the same stream at the same time, but it is not safe
// to call SendMsg on the same stream in different goroutines. It is also
// not safe to call CloseSend concurrently with SendMsg.
//
// It is not safe to modify the message after calling SendMsg. Tracing
// libraries and stats handlers may use the message lazily.
SendMsg(m any) error
```
<!-- Paste the output of SELECT tidb_version() -->

