ID: 16916
Title: Wrong query slow log
Description:
## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. What did you do?

I executed a slow query, and then checked the slow log
```
# Time: 2020-04-28T17:57:11.374857933+08:00
# Txn_start_ts: 416302442381312001
# User: root@ip
# Conn_ID: 2
# Query_time: 42.717773184
# Parse_time: 0.000126594
# Compile_time: 0.000616473
# Process_time: 0.134 Wait_time: 2.237 Backoff_time: 0.114 Request_count: 189 Total_keys: 77491170 Process_keys: 77490981
# DB: sbtest2
# Is_internal: false
# Digest: 8a19b60f48781673db67bf590e937d8e867cfefe1c35b370d5e5a053f8510eab
# Stats: sbtest1:416301587608371205
# Num_cop_tasks: 189
# Cop_proc_avg: 0.000708994 Cop_proc_p90: 0.001 Cop_proc_max: 0.042 Cop_proc_addr: ip1:20160
# Cop_wait_avg: 0.011835978 Cop_wait_p90: 0.002 Cop_wait_max: 0.693 Cop_wait_addr: ip2:20160
# Cop_backoff_staleCommand_total_times: 1 Cop_backoff_staleCommand_total_time: 0.002 Cop_backoff_staleCommand_max_time: 0.002 Cop_backoff_staleCommand_max_addr: ip2:20160 Cop_backoff_staleCommand_avg_time: 0.002 Cop_backoff_staleCommand_p90_time: 0.002
# Cop_backoff_updateLeader_total_times: 56 Cop_backoff_updateLeader_total_time: 0.112 Cop_backoff_updateLeader_max_time: 0.002 Cop_backoff_updateLeader_max_addr: ip2:20160 Cop_backoff_updateLeader_avg_time: 0.002 Cop_backoff_updateLeader_p90_time: 0.002
# Mem_max: 1936
# Prepared: false
# Has_more_results: false
# Succ: true
# Plan: tidb_decode_plan('2gGIMAk1XzIwCTAJMQlmdW5jczpjb3VudChDb2x1bW4jNyktPkMJCyA1CjEJMzFfMjEFLFxkYXRhOlN0cmVhbUFnZ185CjIJNV85CTE6RwAcc2J0ZXN0Mi4JCAgxLmsZUBg3CjMJMV8xATQoNzc0OTA5ODEJbmVCMgA8YywgIiIpCjQJMTBfMTgJMRktFHRhYmxlOg1aSCwga2VlcCBvcmRlcjpmYWxzZQo=')
# Plan_digest: 09a3a7258d6607a25855210ab391d40a8e28ee56af8ffab64bc16137e841a527
select count(k) from sbtest1 where c != "";
```
It's too strange that query time is so large but process time and wait time are so small. I grepped tidb.log using the same ts:
```
[tidb@localhost ~]$ grep 416302442381312001 tidb.log | tail
[2020/04/28 17:57:08.235 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:300.602893ms txnStartTS:416302442381312001 region_id:7029 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:08.688 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:23.098325776s txnStartTS:416302442381312001 region_id:13757 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:08.719 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:22.295158365s txnStartTS:416302442381312001 region_id:14201 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:08.977 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:2.300888376s txnStartTS:416302442381312001 region_id:18229 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:09.300 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:38.66535376s txnStartTS:416302442381312001 region_id:10597 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:09.492 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:1.91851578s txnStartTS:416302442381312001 region_id:18809 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:09.989 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:21.546596486s txnStartTS:416302442381312001 region_id:14701 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:10.237 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:22.837434575s txnStartTS:416302442381312001 region_id:14433 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:10.643 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:28.449324356s txnStartTS:416302442381312001 region_id:12769 store_addr:ip1:20160"] [conn=2]
[2020/04/28 17:57:11.373 +08:00] [INFO] [coprocessor.go:870] ["[TIME_COP_PROCESS] resp_time:8.551136793s txnStartTS:416302442381312001 region_id:17113 store_addr:ip1:20160"] [conn=2]
```
The slow log from TiDB didn't match what tidb.log said. The process time couldn't be less than 1. I also checked TiKV's log, it also said a different result from TiDB slow log:
```
[2020/04/28 17:57:09.305 +08:00] [INFO] [tracker.rs:190] [slow-query] [internal_key_skipped_count=410870] [internal_delete_skipped_count=0] [block_cache_hit_count=18] [block_read_count=1540] [block_read_byte=77544052] [encrypt_data_nanos=0] [decrypt_data_nanos=0] [scan_first_range="Some(start: 7480000000000000595F72800000000153DC79 end: 7480000000000000595F7280000000015A494D)"] [scan_ranges=1] [scan_iter_processed=410870] [scan_iter_ops=410872] [scan_is_desc=false] [tag=select] [table_id=89] [txn_start_ts=416302442381312001] [handler_build_time=0ns] [snapshot_wait_time=1ms] [schedule_wait_time=0ns] [wait_time=1ms] [total_process_time=38.658s] [req_time=38.66s] [peer_id=ipv4:ip:53155] [region_id=10597]
```
### 2. What did you expect to see?
TiDB slow_log should measure time correctly.
### 3. What did you see instead?
It didn't.
### 4. What version of TiDB are you using? (`tidb-server -V` or run `select tidb_version();` on TiDB)
```
> select tidb_version()\G
*************************** 1. row ***************************
tidb_version(): Release Version: v4.0.0-beta.2-352-g5ede18f10
Git Commit Hash: 5ede18f10eedfe2e3690d7728dec3ffa4b0af2d5
Git Branch: master
UTC Build Time: 2020-04-24 03:45:17
GoVersion: go1.13
Race Enabled: false
TiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306
Check Table Before Drop: false
1 row in set (0.00 sec)
```