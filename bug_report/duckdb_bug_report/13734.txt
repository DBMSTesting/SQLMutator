ID: 13734
Title: Nested Structs with Many Keys Cast as JSON and Converted to String in Parquet Output
Description:
### What happens?

**Description:**
I've encountered an issue with DuckDB when handling nested structs with a large number of unique keys. It appears that DuckDB automatically interprets these nested structs as JSON, which results in the column being cast as a `STRING` when the data is written to Parquet. This behavior seems to occur once the number of different keys in the struct exceeds a certain threshold.

I've attached a json file which reproduces this behaviour when queried.
[fragment=0.json](https://github.com/user-attachments/files/16866244/fragment.0.json)

**Expected Behavior:**
The `data` column should retain its nested struct format and not be automatically cast as the JSON data type. This would fix parquet from serializing the data column as a json serialized string.

**Actual Behavior:**
The `data` column is cast as a `STRING` in the Parquet output and as JSON in duckdb.

**Additional Context:**
- This issue seems to arise when the nested struct contains a large number of unique keys.
- The cutoff point for when DuckDB starts interpreting the struct as JSON is unclear, but it seems to be related to the number of keys.


### To Reproduce

1. Generate a nested struct with a significant number of unique keys (e.g., 100 keys).
2. Create multiple rows with these nested structs.
3. DESCRIBE query the file with duckdb

![image](https://github.com/user-attachments/assets/143f0cee-87d5-4665-9332-2accd2430b4b)

**Code Example:**
```python
async def test_nested_structs_with_many_keys_should_not_cast_to_string():
    def generate_unique_dict(keys):
        return {f"{key}@somewhere.com": ["creator", "editor"] for key in keys}

    def generate_random_keys(count):
        return [
            "".join(random.choices(string.ascii_lowercase + string.digits, k=10))
            for _ in range(count)
        ]

    def generate_rows(num_rows):
        rows = []
        for i in range(num_rows):
            keys = generate_random_keys(100)
            rows.append(
                {
                    "id": str(i + 1),
                    "data": generate_unique_dict(keys),
                }
            )
        return rows

    @asset("dict_array_asset_1.parquet")
    async def dict_array_asset_1():
        yield generate_rows(50)
        yield generate_rows(50)

    # Query the composed asset to check its contents
    composed_query = await dict_array_asset_1.query("SELECT * FROM dict_array_asset_1")

    assert composed_query

    # The second column is named data
    assert composed_query.description[1][0] == "data"

    # And it not a string type
    assert composed_query.description[1][1] != "STRING"
```

### OS:

amd64

### DuckDB Version:

1.0.0

### DuckDB Client:

Python

### Full Name:

Maitland Marshall

### Affiliation:

MAIT DEV

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [x] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [x] Yes, I have