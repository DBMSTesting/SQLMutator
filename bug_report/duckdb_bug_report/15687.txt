ID: 15687
Title: Out of Memory Error: failed to allocate data of size 256.0 MiB (260.3 MiB/476.8 MiB used)
Description:
### What happens?

Hello, I am using DuckDB to store logs. When I query logs that meet a certain condition, I encounter an out-of-memory (OOM) issue. Disk spilling is not effective, and I can only increase the memory to complete this query, but memory is expensive. I would like to know how I can complete this query with limited memory. The Parquet file is approximately 120MB, and setting the memory to 500MB causes an OOM error, while increasing it to 600MB allows the query to complete.
memory related config:

| config                       | value           |
|------------------------------|-----------------|
| max_temp_directory_size      | 9.3 GiB         |
| temp_directory               | zion.duckdb.tmp |
| max_memory                   | 476.8 MiB       |
| memory_limit                 | 476.8 MiB       |
| external_threads             | 1               |
| threads                      | 1               |
| worker_threads               | 1               |
| allocator_background_threads | false           |

### To Reproduce

parquet file: https://cdn.functorz.com/log/output1.parquet
query: 

```sql
SELECT json_value(content, '$.bodyBytesSent'), id  from 'output1.parquet' where type in ('GATEWAY');
```

### OS:

mac m1

### DuckDB Version:

1.1.3

### DuckDB Client:

Cli

### Hardware:

Macintosh HD

### Full Name:

shenghui chen

### Affiliation:

momen no code

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have