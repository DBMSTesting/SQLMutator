ID: 16096
Title: OOM On parquet import
Description:
### What happens?

Importing a table from parquet:
`CREATE TABLE IF NOT EXISTS msa AS SELECT * FROM read_parquet('data/2/msa_parquets/*.parquet')`

Out of memory. The files contain two columns, an integer id and a big  VARCHAR. 2500 total files at about 650MB each, total of 2 TB.

1. I have already tried to set max memory has half of the available
2. I have already tried `preserve_insertion_order=false`

### To Reproduce

```sql
SET memory_limit='900GB';
SET preserve_insertion_order = false;
CREATE TABLE IF NOT EXISTS msa AS SELECT * FROM read_parquet('data/2/msa_parquets/*.parquet');
```

### OS:

LSB Version:    :core-4.1-amd64:core-4.1-noarch Distributor ID: RedHatEnterprise Description:    Red Hat Enterprise Linux release 8.8 (Ootpa) Release:        8.8 Codename:       Ootpa

### DuckDB Version:

0.7.1

### DuckDB Client:

Python

### Hardware:

I've tried on a couple of setups. Both Dual socket Intel Xeon Sapphire Rapids 52-core processors (104 cores total). In one case, 256 GB available DDR5 RAM (in which case the above mem limit was lower), and in another 2 TB available.

### Full Name:

Evan Komp

### Affiliation:

National Renewable Energy Lab

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

No - I cannot easily share my data sets due to their large size

### Did you include all code required to reproduce the issue?

- [x] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [x] Yes, I have