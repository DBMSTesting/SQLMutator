ID: 13976
Title: Error when Merging Parquet Files with Nested Structs Containing Different Keys
Description:
### What happens?

I'm experiencing an issue when trying to merge Parquet files using DuckDB. The Parquet files contain nested structs (other_data) with almost identical keys, but some keys are missing or have None values in different rows. When attempting to merge these files, I encounter a type mismatch error related to the nested structs.

### To Reproduce

1. **Prepare the Data**:

   Use the following Python script to generate two JSON files (`rows_1.json` and `rows_2.json`) and convert them into Parquet files (`rows_1.parquet` and `rows_2.parquet`) using DuckDB.

   ```python
   import io
   import json
   import duckdb

   def generate_rows_1():
       rows = [
           {
               "id": "1",
               "data": {
                   "user1@domain.com": {
                       "roles": ["creator", "editor"],
                       "other_data": {
                           "key1": "value1",
                           "key2": "value2"
                           # "key3" is intentionally missing
                       }
                   },
                   "user2@domain.com": {
                       "roles": ["editor"],
                       "other_data": {
                           "key1": "value3",
                           # "key2" is intentionally missing
                           "key3": "value4"
                       }
                   }
               }
           },
           {
               "id": "2",
               "data": {
                   "user3@domain.com": {
                       "roles": ["viewer"],
                       "other_data": {
                           "key1": "value5",
                           "key2": "value6"
                           # "key3" is intentionally missing
                       }
                   }
               }
           }
       ]
       return rows

   def generate_rows_2():
       rows = [
           {
               "id": "3",
               "data": {
                   "user1@domain.com": {
                       "roles": ["creator"],
                       "other_data": {
                           # "key1" is intentionally missing
                           "key2": "value7",
                           "key3": "value8"
                       }
                   },
                   "user4@domain.com": {
                       "roles": ["editor"],
                       "other_data": {
                           "key2": "value9",
                           "key3": "value10",
                           "key4": "value13"  # New key introduced
                       }
                   }
               }
           },
           {
               "id": "4",
               "data": {
                   "user5@domain.com": {
                       "roles": ["viewer"],
                       "other_data": {
                           "key3": "value11",
                           "key4": "value12"
                       }
                   }
               }
           }
       ]
       return rows

   def demo_issue():
       # Generate and write rows_1.json
       rows_1 = generate_rows_1()
       with io.open("rows_1.json", "w") as f:
           json.dump(rows_1, f)

       # Generate and write rows_2.json
       rows_2 = generate_rows_2()
       with io.open("rows_2.json", "w") as f:
           json.dump(rows_2, f)

       # Convert JSON files to Parquet using DuckDB
       duckdb.execute("""
           COPY (SELECT * FROM read_json_auto('rows_1.json'))
           TO 'rows_1.parquet' (FORMAT PARQUET)
       """)
       duckdb.execute("""
           COPY (SELECT * FROM read_json_auto('rows_2.json'))
           TO 'rows_2.parquet' (FORMAT PARQUET)
       """)

       # Attempt to merge the Parquet files
       duckdb.execute("""
           COPY (
               FROM read_parquet('rows_*.parquet', union_by_name = TRUE)
           ) TO 'rows.parquet' (FORMAT PARQUET)
       """)

   if __name__ == "__main__":
       demo_issue()
   ```

2. **Run the Script**:

   Execute the script in an environment with DuckDB installed.

   ```bash
   python demo_issue.py
   ```

**Expected Behavior**:

- The Parquet files `rows_1.parquet` and `rows_2.parquet` should be merged successfully into `rows.parquet`, with DuckDB handling the nested structs and differing keys appropriately.
- Missing keys in the nested structs should be treated as `NULL` or handled according to the `union_by_name = TRUE` parameter.

**Actual Behavior**:

- An error occurs during the merging process.
- **Error Message**:

  ```
  Error while merging Parquet files:
  Mismatch Type Error: Type STRUCT(key2 VARCHAR, key3 VARCHAR) does not match with STRUCT(key1 VARCHAR, key2 VARCHAR). Cannot cast STRUCTs - element "key3" in source struct was not found in target struct
  ```
  
  
**Schema Details**:

- **Schema of `rows_1.parquet`**:

  ```
    column_name                                        column_type null   key default extra
  0          id                                            VARCHAR  YES  None    None  None
  1        data  STRUCT("user1@domain.com" STRUCT(roles VARCHAR...  YES  None    None  None
  ```

- **Schema of `rows_2.parquet`**:

  ```
    column_name                                        column_type null   key default extra
  0          id                                            VARCHAR  YES  None    None  None
  1        data  STRUCT("user1@domain.com" STRUCT(roles VARCHAR...  YES  None    None  None
  ```

### OS:

amd64

### DuckDB Version:

1.1.0

### DuckDB Client:

Python

### Hardware:

_No response_

### Full Name:

Maitland Marshall

### Affiliation:

MAIT DEV

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have