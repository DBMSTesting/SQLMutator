ID: 14204
Title: Cannot parse large json
Description:
### What happens?

We tried to download this file: https://nyp.acquiadam.com/assets/share/asset/hisgjrgpuk
https://www.nyp.org/patients-visitors/paying-for-care/hospital-price-transparency/standard-charges

tried parsing using the following duckdb code: 

```sql
SELECT *
FROM read_json('./133957095_NewYork-PresbyterianHospital_standardcharges.json.json', 
maximum_object_size=1677721,
    columns={
        'description': 'VARCHAR',
        'drug_information.unit': 'VARCHAR',
        'drug_information.type': 'VARCHAR',
        'code_information.code': 'VARCHAR',
        'code_information.type': 'VARCHAR',
        'standard_charges.setting': 'VARCHAR',
        'standard_charges.gross': 'DOUBLE',
        'standard_charges.discounted_cash': 'DOUBLE',
        'standard_charges.minimum': 'DOUBLE',
        'standard_charges.maximum': 'DOUBLE',
        'standard_charges.payers_information.payer_name': 'VARCHAR',
        'standard_charges.payers_information.plan_name': 'VARCHAR',
        'standard_charges.payers_information.standard_charge_dollar': 'DOUBLE',
        'standard_charges.payers_information.methodology': 'VARCHAR',
        'standard_charges.payers_information.additional_payer_notes': 'VARCHAR'
    })
LIMIT 10;
```
yielding this error
```
RuntimeError: (duckdb.duckdb.InvalidInputException) Invalid Input Error: "maximum_object_size" of 16777216 bytes exceeded while reading file "./133957095_NewYork-PresbyterianHospital_standardcharges.json.json" (>33554428 bytes).
 Try increasing "maximum_object_size".
[SQL: SELECT *
FROM read_json('./133957095_NewYork-PresbyterianHospital_standardcharges.json.json',
maximum_object_size=1677721,
    columns={
        'description': 'VARCHAR',
        'drug_information.unit': 'VARCHAR',
        'drug_information.type': 'VARCHAR',
        'code_information.code': 'VARCHAR',
        'code_information.type': 'VARCHAR',
        'standard_charges.setting': 'VARCHAR',
        'standard_charges.gross': 'DOUBLE',
        'standard_charges.discounted_cash': 'DOUBLE',
        'standard_charges.minimum': 'DOUBLE',
        'standard_charges.maximum': 'DOUBLE',
        'standard_charges.payers_information.payer_name': 'VARCHAR',
        'standard_charges.payers_information.plan_name': 'VARCHAR',
        'standard_charges.payers_information.standard_charge_dollar': 'DOUBLE',
        'standard_charges.payers_information.methodology': 'VARCHAR',
        'standard_charges.payers_information.additional_payer_notes': 'VARCHAR'
    })
LIMIT 10;]
(Background on this error at: https://sqlalche.me/e/20/f405)
If you need help solving this issue, send us a message: https://ploomber.io/community
```

I am volunteering at @OneFact working with @JaanLi



### To Reproduce

See above

### OS:

Mac

### DuckDB Version:

Pre-release

### DuckDB Client:

python

### Hardware:

_No response_

### Full Name:

Anas Anam

### Affiliation:

OneFact

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a nightly build

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have