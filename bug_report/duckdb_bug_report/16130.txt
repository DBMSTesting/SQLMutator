ID: 16130
Title: Performance: Duckdb 10x slower than PyArrow
Description:
### What happens?

I have a set of geoparquest files stored on s3 using a hive partitioning (year/month/day). The parquet files are sorted by device_id. There are a total of 63 files that take 28GB. The biggest one is about 1.8GB. The results from DuckDB and PyArrow are exactly the same. But DuckDB takes 35 seconds and pyarrow takes 2.5 seconds.

This is on Windows, but see the same on MacOS and Redhat UBI.

The query looks like this:

```
     SELECT *
     FROM dataset
     WHERE year = 2025 AND
           month = 1 AND
           day = 1 AND
           device_id = ANY($1) AND 
           mmsi = ANY($2)
```

Where hashed_ids is:

```
hashed_ids = ['39909B0F770B2FE', '5461B673F57D9C40', '5909574FA3381E23', '194E7ADEA5BD39EA',
              '765725A10D8F547C', '52F9DAA4DC4B508D', 'C65643A6261327CB', '81E821A9D5E14955',
              '4230E6F93DA7E690', '783528C60FEC0F6A', 'FFA69D17477A575A', '9D91D17E63EE72AC',
              '36D16108A1240F03', '3650799870AA295', '131B19045DA7F33F', 'EA9FBF683F5EC45E',
              '91A87F25D65AF210', 'D3A18541C406A4EA']
```

I have not included the mmsis because I can't share those, but its another array.

In PyArrow:

```
    filter = (
            (pc.field('year') == 2025) &
            (pc.field('month') == 1) &
            (pc.field('day') == 1) &
            (pc.field('device_id').isin(hashed_ids)) &
            (pc.field('mmsi').isin(mmsis))
    )
    filtered = dataset.filter(filter)
```

Setting the ENV `ARROW_S3_LOG_LEVEL` to DEBUG shows that duckdb and pyarrow read the same 4 parquet files. It also shows that DuckDB reads many more byte ranges and will read the same byte range several times. I have those logs too if it is helpful. This is mostly happening against a 1.8GB parquet file which I assume is resulting in the slowdown.

I can probably share the 1.8GB parquet file if needed. I have also built a debug build of DuckDB and can investigate further if needed - however I am new to DuckDB so would need a bit of direction as to where to look.



### To Reproduce

This issue is 100% reproducible in both my local setup and on AWS.

### OS:

Windows 11

### DuckDB Version:

1.2

### DuckDB Client:

Python 3.13.1

### Hardware:

Client - Thinkpad X1 Meteor Lake, 64GB Ram. Server - Think Station Raptor Lake 64GB Memory 4TB storage SSD

### Full Name:

Charlie Savage

### Affiliation:

Orbital Insight

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

No - Other reason (please specify in the issue body)

### Did you include all code required to reproduce the issue?

- [x] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [x] Yes, I have