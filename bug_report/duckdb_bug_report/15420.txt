ID: 15420
Title: ART index creation takes too much memory
Description:
### What happens?

I used the data of TPCH-100G and add the index to the lineitem table as follows(l_orderkey is bigint, l_linenumber is int)

```
set threads = 4;
set memory_limit = '20GB';
create unique index ii on lineitem(l_orderkey, l_linenumber);
47% ▕████████████████████████████▏    
Out of Memory Error: could not allocate block of size 256.0 KiB (18.6 GiB/18.6 GiB used)
```

The size of the `lineitem` table is only 18GB, but OOM still occurs.
I suspect that the create index loads all data into memory and does not do the necessary buffer eviction.

### To Reproduce

```sql
INSTALL tpch;
LOAD tpch;
CALL dbgen(sf = 100);
set threads = 4;
set memory_limit = '20GB';
create unique index ii on lineitem(l_orderkey, l_linenumber);
```

### OS:

linux

### DuckDB Version:

1.1.3

### DuckDB Client:

duckapi-c

### Hardware:

x86-64

### Full Name:

fanvanzh

### Affiliation:

fanvanzh

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a source build

### Did you include all relevant data sets for reproducing the issue?

No - Other reason (please specify in the issue body)

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have