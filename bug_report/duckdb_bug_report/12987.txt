ID: 12987
Title: Lifetime issue with view created in experimental Spark API
Description:
### What happens?

The context is that I am trying to change my application to be able to use either pyspark or your experimental Spark API. There are many cases where I am using Spark functions that you haven't implemented. In these cases, instead of using the DataFrame API, I am doing the following: (1) create a view (2) send a direct SQL query to that view, (3) delete all temp views eventually.

Querying a view when re-using a variable name fails in v1.0.0. It passes in v0.10.2. If I am doing something wrong, or if there is a better way, please let me know.

A workaround is to:
1. Create a view, as shown
2. Create a table from that view (`CREATE TABLE my_table AS SELECT * from tmp_view`).
3. Use the table going forward.

### To Reproduce

Copy this code into a script, such as `view.py`. 
```
from uuid import uuid4

from duckdb.experimental.spark.sql import DataFrame, SparkSession
import duckdb.experimental.spark.sql.functions as F

def create_tmp_view(df: DataFrame) -> str:
    view = f"tmp_{uuid4().hex}"
    df.createOrReplaceTempView(view)
    return view

def main():
    df = spark.createDataFrame([(2, "Alice"), (2, "Bob"), (2, "Bob"), (5, "Bob")], schema=["age", "name"])
    view = create_tmp_view(df)
    df = spark.sql(f"SELECT * FROM {view} WHERE name = 'Alice'")
    print(df.collect())

if __name__ == "__main__":
    spark = SparkSession.builder.getOrCreate()
    main()
```

Run `python view.py` in the terminal.
```
Traceback (most recent call last):
  File "./view.py", line 19, in <module>
    main()
  File "./view.py", line 15, in main
    print(df.collect())
          ^^^^^^^^^^^^
  File "/Users/dthom/python-envs/duckdb/lib/python3.11/site-packages/duckdb/experimental/spark/sql/dataframe.py", line 981, in collect
    result = self.relation.fetchall()
             ^^^^^^^^^^^^^^^^^^^^^^^^
duckdb.duckdb.InvalidInputException: Invalid Input Error: Attempting to execute an unsuccessful or closed pending query result
Error: Invalid Error: vector
```
If I change the variable name of the result of the query to `df2`, as in
```
    df2 = spark.sql(f"SELECT * FROM {view} WHERE name = 'Alice'")
    print(df2.collect())
```
it works.

The original code works in v0.10.2. It seems to me that the view should not be tied to the variable instance.


### OS:

MacOS aarch64

### DuckDB Version:

1.0.0

### DuckDB Client:

Python

### Full Name:

Daniel Thom

### Affiliation:

National Renewable Energy Laboratory (NREL)

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a source build

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have