ID: 13697
Title: Provide workaround for prefetching parquet files with incorrect page offsets
Description:
Fixes the following bug:
```
SELECT * from read_parquet("https://github.com/apache/arrow/raw/main/r/inst/v0.7.1.parquet");
```
Leading to
```
Invalid Input Error: Malformed parquet file: sum of total compressed bytes of columns seems incorrect
```

### why this happens?
The reason is that in the respective parquet file the index_page_offset fields are set to 0. DuckDB uses this value to compute the byte range that needs to be prefetched for this column chunk. This prefetching mechanism now no longer works properly because DuckDB can not easily determine the byte ranges to prefetch

### The fix
The workaround is to add an option that disables the Prefetching mechanism and hinting the users to use that option. This will disable the prefetching mechanism for these files allowing them to be scanned.

To be able to test this easily I also added the debug option `prefetch_all_parquet_files`