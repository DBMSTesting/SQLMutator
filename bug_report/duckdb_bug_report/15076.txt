ID: 15076
Title: csv file with empty column is auto inferred as VARCHAR.
Description:
### What happens?

When reading multiples csv, if one have an column without any data, it's column type is inferred to VARCHAR.  
This lead to the following error:  

```
Invalid Input Error: Schema mismatch between globbed files.
Main file schema: 1-1-2024-11-08T10-01-41.339Z.csv
Current file: 1-110-2024-11-08T17-24-29.005Z.csv
Column with name: "Player ID" is expected to have type: BIGINT But has type: VARCHAR
Potential Fix: Since your schema has a mismatch, consider setting union_by_name=true.
```

### To Reproduce

[1-1-2024-11-08T10-01-41.339Z.csv](https://github.com/user-attachments/files/17969559/1-1-2024-11-08T10-01-41.339Z.csv)
[1-110-2024-11-08T17-24-29.005Z.csv](https://github.com/user-attachments/files/17969560/1-110-2024-11-08T17-24-29.005Z.csv)

With theses two file in a directory, run:  
`select * from "*.csv";`

### OS:

Windows

### DuckDB Version:

v1.1.3 19864453f7

### DuckDB Client:

CLI

### Hardware:

_No response_

### Full Name:

Nicolas Vandeginste

### Affiliation:

@Abc-Arbitrage (this bug was found while using DuckDB for personal usage)

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have