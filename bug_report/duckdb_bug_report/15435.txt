ID: 15435
Title: [Parquet] Option to not cache union readers
Description:
I have a niche use case where I want to scan a large amount of Parquet files, each with very large schemas (hundreds of columns, long column names, many nested columns), with `union_by_name=True`. [The benchmark I added](https://github.com/thalassemia/duckdb/blob/2838e311550ed631d206f58c1a1a2cc5690bee82/benchmark/parquet/large_schema_union_by_name.benchmark) exemplifies this use case. Changing the run command to `repeat` 1,000,000 times, `main` used upwards of 40GB of RAM on my machine. Almost all of this is from caching of Parquet readers (including metadata/schema) when running with `union_by_name=True`. With this PR, even 1,000,000 repeats required less than 2GB of RAM to run.

I made this an opt-in feature because of the potential performance penalty from having to remake the readers. However, on fast local SSD storage, the benchmark I added is not significantly slower with my PR versus without.