ID: 15674
Title: free(): corrupted unsorted chunks error on duckdb python insert script within a transaction
Description:
### What happens?

When I run a python script inserting data into a DuckDB database, I get:

```
free(): corrupted unsorted chunks
Aborted (core dumped)
```

here's the backtrace with gdb:

```
(gdb) bt
#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:44
#1  __pthread_kill_internal (signo=6, threadid=<optimized out>) at ./nptl/pthread_kill.c:78
#2  __GI___pthread_kill (threadid=<optimized out>, signo=signo@entry=6) at ./nptl/pthread_kill.c:89
#3  0x000071bf1824526e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26
#4  0x000071bf182288ff in __GI_abort () at ./stdlib/abort.c:79
#5  0x000071bf182297b6 in __libc_message_impl (fmt=fmt@entry=0x71bf183ce8d7 "%s\n") at ../sysdeps/posix/libc_fatal.c:132
#6  0x000071bf182a8fe5 in malloc_printerr (str=str@entry=0x71bf183d1b68 "free(): corrupted unsorted chunks") at ./malloc/malloc.c:5772
#7  0x000071bf182ab154 in _int_free_create_chunk (nextsize=48, nextchunk=0x180e91a0, size=192, p=0x180e90e0, av=0x71bf18403ac0 <main_arena>) at ./malloc/malloc.c:4735
#8  _int_free_merge_chunk (av=0x71bf18403ac0 <main_arena>, p=0x180e90e0, size=<optimized out>) at ./malloc/malloc.c:4700
#9  0x000071bf182ab42a in _int_free (av=0x71bf18403ac0 <main_arena>, p=<optimized out>, have_lock=<optimized out>) at ./malloc/malloc.c:4646
#10 0x000071bf182add9e in __GI___libc_free (mem=0x180e90f0) at ./malloc/malloc.c:3398
#11 0x000071bf164141b7 in duckdb::BufferEvictionNode::TryGetBlockHandle() () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#12 0x000071bf16416d07 in duckdb::EvictionQueue::PurgeIteration(unsigned long) () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#13 0x000071bf16417965 in duckdb::EvictionQueue::Purge() () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#14 0x000071bf1641385d in duckdb::BufferHandle::Destroy() () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#15 0x000071bf1643dc56 in void duckdb::RLEFinalizeCompress<int, true>(duckdb::CompressionState&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#16 0x000071bf1650473c in duckdb::ColumnDataCheckpointer::WriteToDisk() () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#17 0x000071bf16504a90 in duckdb::ColumnData::Checkpoint(duckdb::RowGroup&, duckdb::ColumnCheckpointInfo&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#18 0x000071bf1650500c in duckdb::StandardColumnData::Checkpoint(duckdb::RowGroup&, duckdb::ColumnCheckpointInfo&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#19 0x000071bf165083f0 in duckdb::RowGroup::WriteToDisk(duckdb::RowGroupWriteInfo&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#20 0x000071bf163eccd7 in duckdb::OptimisticDataWriter::FlushToDisk(duckdb::RowGroup&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#21 0x000071bf15de1690 in duckdb::CollectionMerger::Flush(duckdb::OptimisticDataWriter&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#22 0x000071bf15dd1fd4 in duckdb::PhysicalBatchInsert::Finalize(duckdb::Pipeline&, duckdb::Event&, duckdb::ClientContext&, duckdb::OperatorSinkFinalizeInput&) const ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#23 0x000071bf16288378 in duckdb::PipelineFinishTask::ExecuteTask(duckdb::TaskExecutionMode) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#24 0x000071bf1627b512 in duckdb::ExecutorTask::Execute(duckdb::TaskExecutionMode) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#25 0x000071bf1627fac4 in duckdb::Executor::ExecuteTask(bool) () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#26 0x000071bf1613ac53 in duckdb::ClientContext::ExecuteTaskInternal(duckdb::ClientContextLock&, duckdb::BaseQueryResult&, bool) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#27 0x000071bf1613c022 in duckdb::PendingQueryResult::ExecuteTask() () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#28 0x000071bf165cacfa in duckdb::DuckDBPyConnection::CompletePendingQuery(duckdb::PendingQueryResult&) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#29 0x000071bf165d95f4 in duckdb::DuckDBPyConnection::ExecuteInternal(duckdb::PreparedStatement&, pybind11::object) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#30 0x000071bf165dfc89 in duckdb::DuckDBPyConnection::Execute(pybind11::object const&, pybind11::object) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#31 0x000071bf165f9d6f in pybind11::cpp_function::initialize<pybind11::cpp_function::initialize<duckdb::shared_ptr<duckdb::DuckDBPyConnection, true>, duckdb::DuckDBPyConnection, pybind11::object const&, pybind11::object, pybind11::name, pybind11::is_method, pybind11::sibling, char [86], pybind11::arg, pybind11::arg_v>(duckdb::shared_ptr<duckdb::DuckDBPyConnection, true> (duckdb::DuckDBPyConnection::*)(pybind11::object const&, pybind11::object), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&, char const (&) [86], pybind11::arg const&, pybind11::arg_v const&)::{lambda(duckdb::DuckDBPyConnection*, pybind11::object const&, pybind11::object)#1}, duckdb::shared_ptr<duckdb::DuckDBPyConnection, true>, duckdb::DuckDBPyConnection*, pybind11::object const&, pybind11::object, pybind11::name, pybind11::is_method, pybind11::sibling, char [86], pybind11::arg, pybind11::arg_v>(pybind11::cpp_function::initialize<duckdb::shared_ptr<duckdb::DuckDBPyConnection, true>, duckdb::DuckDBPyConnection, pybind11::object const&, pybind11::object, pybind11::name, pybind11::is_method, pybind11::sibling, char [86], pybind11::arg, pybind11::arg_v>(duckdb::shared_ptr<duckdb::DuckDBPyConnection, true> (duckdb::DuckDBPyConnection::*)(pybind11::object const&, pybind11::object), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&, char const (&) [86], pybind11::arg const&, pybind11::arg_v const&)::{lambda(duckdb::DuckDBPyConnection*, pybind11::object const&, pybind11::object)#1}&&, duckdb::shared_ptr<duckdb::DuckDBPyConnection, true> (*)(duckdb::DuckDBPyConnection*, pybind11::object const&, pybind11::object), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&, char const (&) [86], pybind11::arg const&, pybind11::arg_v const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call&) () from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#32 0x000071bf16561bd3 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) ()
   from /home/akos/src/algotrading/etc/venv/lib/python3.12/site-packages/duckdb/duckdb.cpython-312-x86_64-linux-gnu.so
#33 0x00000000005820ff in ?? ()
#34 0x0000000000548ec5 in _PyObject_MakeTpCall ()
#35 0x00000000005d74d9 in _PyEval_EvalFrameDefault ()
#36 0x00000000005d59fb in PyEval_EvalCode ()
#37 0x0000000000608b52 in ?? ()
#38 0x00000000006b4d83 in ?? ()
#39 0x00000000006b4aea in _PyRun_SimpleFileObject ()
#40 0x00000000006b491f in _PyRun_AnyFileObject ()
#41 0x00000000006bc985 in Py_RunMain ()
#42 0x00000000006bc46d in Py_BytesMain ()
#43 0x000071bf1822a1ca in __libc_start_call_main (main=main@entry=0x518850, argc=argc@entry=8, argv=argv@entry=0x7fff9fbce108) at ../sysdeps/nptl/libc_start_call_main.h:58
#44 0x000071bf1822a28b in __libc_start_main_impl (main=0x518850, argc=8, argv=0x7fff9fbce108, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fff9fbce0f8)
    at ../csu/libc-start.c:360
#45 0x0000000000657c15 in _start ()

```

### To Reproduce

See the script that causes the problem below. The issue surfaces in the 'Processing CSV files' phase. If I don't do it in a transaction (remove the 'BEGIN TRANSACTION' and 'COMMIT' statements), it doesn't produce the error.

The data processed comes from polygon.io flat files: https://polygon.io/flat-files/stocks-trades , a sample file is available here: https://polygon.io/flat-files/stocks-trades?stocks-trades=documentation

```
import os
import argparse
import glob
import duckdb

import numpy as np
import pandas as pd

from tqdm import tqdm

dtype = {
    'ticker': 'str',
    'conditions': 'str',
    'correction': 'int',
    'exchange': 'str',
    'id': 'str',  # read as 'str' as sometimes there is no value provided. convert to int later
    'participant_timestamp': 'int',  # Use 'int' and convert to datetime later if needed
    'price': 'float',
    'sequence_number': 'int',
    'sip_timestamp': 'int',  # Use 'int' and convert to datetime later if needed
    'size': 'int',
    'tape': 'str',
    'trf_id': 'int',
    'trf_timestamp': 'int'  # Use 'int' and convert to datetime later if needed
}

def main(input_dir, symbols, output_database):
    # Connect to DuckDB with persistent storage
    conn = duckdb.connect(database=output_database, read_only=False)

    conn.execute("SET timezone = 'UTC';")

    conn.execute("BEGIN TRANSACTION")

    print("Processing CSV files...")

    # Define the path to your Parquet files
    csv_files = sorted(glob.glob(os.path.join(input_dir, '**/*.csv.gz'), recursive=True))

    # Check if the schema 'stock_trades_polygon' exists and create it if needed
    schema_exists = conn.execute("""SELECT COUNT(*) FROM information_schema.schemata WHERE schema_name = 'stock_trades_polygon'""").fetchone()[0]
    if schema_exists == 0:
        conn.execute("CREATE SCHEMA stock_trades_polygon")

    progress_bar = tqdm(csv_files, desc="Processing CSV files")
    for i, csv_file in enumerate(progress_bar):
        progress_bar.set_description(f"{os.path.basename(csv_file)}")

        df = pd.DataFrame()
        chunk_size = 10_000_000
        for chunk in pd.read_csv(csv_file, compression='gzip', chunksize=chunk_size, dtype=dtype, low_memory=False):
            if symbols is not None:
                chunk = chunk[chunk['ticker'].isin(symbols)]
            df = pd.concat([df, chunk])

        df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)

        df['participant_timestamp'] = df['participant_timestamp'].replace(0, np.nan)
        df['sip_timestamp'] = df['sip_timestamp'].replace(0, np.nan)
        df['trf_timestamp'] = df['trf_timestamp'].replace(0, np.nan)

        df['participant_timestamp'] = pd.to_datetime(df['participant_timestamp'], unit='ns', errors='coerce', utc=True)
        df['sip_timestamp'] = pd.to_datetime(df['sip_timestamp'], unit='ns', errors='coerce', utc=True)
        df['trf_timestamp'] = pd.to_datetime(df['trf_timestamp'], unit='ns', errors='coerce', utc=True)

        ticker_progress_bar = tqdm(sorted(df['ticker'].unique()), desc="Processing tickers", leave=False)
        for i, ticker in enumerate(ticker_progress_bar):
            ticker_progress_bar.set_description(f"{ticker}")
            df_symbol = df[df['ticker'] == ticker]

            try:
                # Check if the table exists
                tables = conn.execute(f"select table_name FROM information_schema.tables where table_name = 'temp_import_{ticker}' and table_schema = 'stock_trades_polygon';").fetchall()
                if len(tables) == 0:
                    conn.execute(f"""
                        CREATE TABLE stock_trades_polygon.temp_import_{ticker} (
                            ticker VARCHAR,
                            conditions VARCHAR,
                            correction INTEGER,
                            exchange VARCHAR,
                            id BIGINT,
                            participant_timestamp TIMESTAMPTZ,
                            price DOUBLE,
                            sequence_number BIGINT,
                            sip_timestamp TIMESTAMPTZ,
                            size INTEGER,
                            tape VARCHAR,
                            trf_id INTEGER,
                            trf_timestamp TIMESTAMPTZ
                        )
                    """)

                conn.execute(f"""
                    INSERT INTO stock_trades_polygon.temp_import_{ticker}
                    SELECT * from df_symbol
                """)
            except Exception as e:
                print(f"Error processing ticker {ticker}: {e}")

    print("Processing CSV files done.")

    print("Sorting data for each ticker...")

    # insert the data into its final destination, ordered by timestamp
    progress_bar = tqdm(sorted(df['ticker'].unique()), desc="Sorting data for each ticker")
    for i, ticker in enumerate(progress_bar):
        progress_bar.set_description(f"{ticker}")
        try:
            # Check if the table exists
            tables = conn.execute(f"select table_name FROM information_schema.tables where table_name = '{ticker}' and table_schema = 'stock_trades_polygon';").fetchall()
            if len(tables) > 0:
                # If the table exists, insert the data into the existing table
                conn.execute(f"""
                    INSERT INTO stock_trades_polygon.{ticker}
                    SELECT ticker, conditions, correction, exchange, id, participant_timestamp, price, sequence_number,
                           sip_timestamp, size, tape, trf_id, trf_timestamp
                    FROM stock_trades_polygon.temp_import_{ticker}
                    ORDER BY sip_timestamp
                """)
            else:
                # If the table doesn't exist, create it and insert the data
                conn.execute(f"""
                    CREATE TABLE stock_trades_polygon.{ticker} AS 
                    SELECT ticker, conditions, correction, exchange, id, participant_timestamp, price, sequence_number,
                           sip_timestamp, size, tape, trf_id, trf_timestamp
                    FROM stock_trades_polygon.temp_import_{ticker}
                    ORDER BY sip_timestamp
                """)

            # Drop the temporary table
            conn.execute(f"DROP TABLE stock_trades_polygon.\"temp_import_{ticker}\"")
        except Exception as e:
            print(f"Error processing ticker {ticker}: {e}")

    print("Sorting data for each ticker done.")

    print("Committing changes...")

    conn.execute("COMMIT")

    print("Committing changes done.")

    # Commit the changes
    conn.commit()

if __name__ == '__main__':
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Convert CSV flat files from Polygon into a DuckDB database.')
    parser.add_argument('--input-dir', required=True, help='The directory containing the input CSV files')
    parser.add_argument('--symbols', required=False, default=None, help='Comma-delimited list of symbols to import from the CSV files, defaults to all symbols')
    parser.add_argument('--output-database', required=True, help='The DuckDB database file to write the output to')
    args = parser.parse_args()

    input_dir = args.input_dir
    symbols = args.symbols.split(',') if args.symbols is not None else None
    output_database = args.output_database

    main(input_dir, symbols, output_database)
```

### OS:

Linux Mint 22

### DuckDB Version:

1.1.3

### DuckDB Client:

Python 3.12.3

### Hardware:

AMD Ryzen 9 5950X 16-Core Processor, 128GB RAM

### Full Name:

Ákos Maróy

### Affiliation:

n/a

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have not tested with any build

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have