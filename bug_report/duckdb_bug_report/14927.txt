ID: 14927
Title: Binder Error: Unknown option for COPY ... TO ... (FORMAT JSON): "partition_by".
Description:
### What happens?

From what I gather, JSON write should support hive partitioning. [From the docs](https://duckdb.org/docs/sql/statements/copy.html#copy--to-options):

```
The below options are applicable to all formats written with COPY.
```

But it appears that it only works with parquet and CSV.

```
memory.main> COPY (SELECT uuid() AS id, 'foo' AS data) TO 'documents/random_sample' (FORMAT CSV, PARTITION_BY (id))
[2024-11-20 17:19:44] 1 row affected in 6 ms
```
```
memory.main> COPY (SELECT uuid() AS id, 'foo' AS data) TO 'documents/random_sample' (FORMAT PARQUET, PARTITION_BY (id))
[2024-11-20 17:20:15] 1 row affected in 6 ms
```
```
memory.main> COPY (SELECT uuid() AS id, 'foo' AS data) TO 'documents/random_sample' (FORMAT JSON, PARTITION_BY (id))
[2024-11-20 17:20:40] Binder Error: Unknown option for COPY ... TO ... (FORMAT JSON): "partition_by".
```

### To Reproduce

```
COPY (SELECT uuid() AS id, 'foo' AS data) TO 'cannot_write' (FORMAT JSON, PARTITION_BY (id));
```

### OS:

Arch Linux x86_64

### DuckDB Version:

DuckDB (ver. v1.1.1)

### DuckDB Client:
DuckDBJ (ver. 1.0, JDBC1.0)
DuckDB CLI v1.1.3 19864453f7

### Hardware:

_No response_

### Full Name:

Aksel Hjalmarsson Tórgarð

### Affiliation:

Matter DK ApS

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a stable release

### Did you include all relevant data sets for reproducing the issue?

Yes

### Did you include all code required to reproduce the issue?

- [X] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [X] Yes, I have