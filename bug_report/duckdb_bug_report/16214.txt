ID: 16214
Title: Writing parquet with generate_series and per_thread_output
Description:
### What happens?

The sample code on  https://duckdb.org/docs/data/parquet/tips.html 
with enabling PER_THREAD_OUTPUT does not work. Only one file is created:


### To Reproduce

```SQL
COPY
    (FROM generate_series(10_000_000))
    TO 'test'
    (FORMAT PARQUET, PER_THREAD_OUTPUT);
```
After Materializing the series and disabling preserve_insertion_order files are written in parallel: 
```SQL
set preserve_insertion_order to false;

COPY
(
    with series as materialized
    (
        select i FROM generate_series(0,1_000_000) as s(i)
    )
    from series
)    
TO 'test' 
(FORMAT PARQUET, PER_THREAD_OUTPUT,overwrite);
```

### OS:

Windows 11

### DuckDB Version:

v1.2.1-dev212

### DuckDB Client:

Python 3.11.11 notebook

### Hardware:

VM 32gb, 8 cores

### Full Name:

Christoph Mettler

### Affiliation:

Ethenea

### What is the latest build you tested with? If possible, we recommend testing with the latest nightly build.

I have tested with a nightly build

### Did you include all relevant data sets for reproducing the issue?

Not applicable - the reproduction does not require a data set

### Did you include all code required to reproduce the issue?

- [x] Yes, I have

### Did you include all relevant configuration (e.g., CPU architecture, Python version, Linux distribution) to reproduce the issue?

- [x] Yes, I have