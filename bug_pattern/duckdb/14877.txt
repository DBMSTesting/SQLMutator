{
    "pattern": "COPY (SELECT <select_parameter> TRIM(<string_function_parameter>, concat(' ', chr(9), chr(10), chr(13))) AS <alias_parameter>, IF(TRIM(<string_function_parameter>, concat(' ', chr(9), chr(10), chr(13))) != '', TRIM(<string_function_parameter>, concat(' ', chr(9), chr(10), chr(13))), null) AS <alias_parameter> FROM <table_name_parameter>) TO <string_parameter> (FORMAT <format_parameter>, HEADER <header_parameter> , DELIMITER <string_parameter>, ESCAPE <string_parameter>, QUOTE <string_parameter>, DATEFORMAT <string_parameter>, TIMESTAMPFORMAT <string_parameter>, COMPRESSION <string_parameter>, NULLSTR <string_parameter>, USE_TMP_FILE <boolean_parameter>, FORCE_QUOTE(<column_name_parameter>,<column_name_parameter>));",
    "applied_rules": [
        "<select_parameter>",
        "<string_function_parameter>",
        "<alias_parameter>",
        "<table_name_parameter>",
        "<string_parameter>",
        "<format_parameter>",
        "<header_parameter>",
        "<boolean_parameter>",
        "<column_name_parameter>"
    ],
    "Affected Elements": "USE_TMP_FILE, COMPRESSION 'gzip', COPY",
    "Root Cause Analysis": "The underlying issue is likely related to how DuckDB handles temporary files during multipart uploads to S3 when gzip compression is applied, causing uploads to hang and not finalize correctly."
}